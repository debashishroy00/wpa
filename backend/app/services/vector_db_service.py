"""
Vector Database Service for Financial Data
Stores embeddings of user financial information for semantic search
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import json
import hashlib
from typing import List, Dict, Any, Optional
from datetime import datetime
import structlog
from sqlalchemy.orm import Session

logger = structlog.get_logger()

class FinancialVectorDB:
    def __init__(self):
        # Initialize ChromaDB with persistent storage (CRITICAL FIX)
        self.client = chromadb.PersistentClient(path="/app/vector_db")
        
        # Initialize embedding model (all-MiniLM-L6-v2 is fast and accurate)
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Create or get collection for financial data
        self.collection = self.client.get_or_create_collection(
            name="financial_data",
            metadata={"description": "User financial information embeddings"}
        )
        
        logger.info("FinancialVectorDB initialized successfully")
    
    def index_comprehensive_summary(self, user_id: int, summary: dict):
        """
        Index the comprehensive summary into vector database
        Break down into semantic chunks for better retrieval
        """
        
        documents = []
        metadatas = []
        ids = []
        
        # 1. Index User Profile
        profile_text = f"""
        User: {summary['user']['name']}
        Age: {summary['user']['age']}
        Email: {summary['user']['email']}
        Account Status: {summary['user']['status']}
        """
        documents.append(profile_text)
        metadatas.append({
            "user_id": user_id,
            "category": "profile",
            "subcategory": "basic_info",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_profile")
        
        # 2. Index Financial Preferences
        preferences = summary.get('preferences', {})
        pref_text = f"""
        Risk Tolerance: {preferences.get('risk_tolerance', 'not set')}
        Risk Score: {preferences.get('risk_score', 0)}/10
        Investment Style: {preferences.get('investment_style', 'not set')}
        Investment Timeline: {preferences.get('investment_timeline', 0)} years
        Financial Knowledge: {preferences.get('financial_knowledge', 'not set')}
        Emergency Fund Target: {preferences.get('emergency_fund_months', 6)} months
        Tax Filing Status: {preferences.get('tax_filing_status', 'not set')}
        Federal Tax Bracket: {preferences.get('federal_tax_bracket', 0)*100 if preferences.get('federal_tax_bracket') else 0}%
        State: {preferences.get('state', 'not set')}
        State Tax Rate: {preferences.get('state_tax_rate', 0)*100 if preferences.get('state_tax_rate') else 0}%
        Stocks Preference: {preferences.get('stocks_preference', 0)}/10
        Bonds Preference: {preferences.get('bonds_preference', 0)}/10
        Real Estate Preference: {preferences.get('real_estate_preference', 0)}/10
        Crypto Preference: {preferences.get('crypto_preference', 0)}/10
        ESG Investing: {preferences.get('esg_investing', False)}
        Tax Loss Harvesting: {preferences.get('tax_loss_harvesting', False)}
        """
        documents.append(pref_text)
        metadatas.append({
            "user_id": user_id,
            "category": "preferences",
            "subcategory": "investment_preferences",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_preferences")
        
        # 3. Index Financial Summary
        financials = summary.get('financials', {})
        summary_text = f"""
        Net Worth: ${financials.get('netWorth', 0):,.2f}
        Total Assets: ${financials.get('totalAssets', 0):,.2f}
        Total Liabilities: ${financials.get('totalLiabilities', 0):,.2f}
        Monthly Income: ${financials.get('monthlyIncome', 0):,.2f}
        Monthly Expenses: ${financials.get('monthlyExpenses', 0):,.2f}
        Monthly Surplus: ${financials.get('monthlySurplus', 0):,.2f}
        Savings Rate: {financials.get('savingsRate', 0)}%
        Debt-to-Income Ratio: {financials.get('debtToIncomeRatio', 0)}%
        Emergency Fund Coverage: {financials.get('emergencyFundCoverage', 0)} months
        """
        documents.append(summary_text)
        metadatas.append({
            "user_id": user_id,
            "category": "financials",
            "subcategory": "summary",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_financial_summary")
        
        # 4. Index Assets by Category
        assets = financials.get('assets', {})
        
        # Real Estate
        if 'realEstate' in assets:
            real_estate_items = []
            for item in assets['realEstate']:
                real_estate_items.append(f"{item['name']}: ${item['value']:,.2f}")
            real_estate_text = f"""
            Real Estate Assets (Total: ${financials['assetAllocation']['realEstate']['value']:,.2f}):
            {chr(10).join(real_estate_items)}
            Real Estate Allocation: {financials['assetAllocation']['realEstate']['percentage']}%
            """
            documents.append(real_estate_text)
            metadatas.append({
                "user_id": user_id,
                "category": "assets",
                "subcategory": "real_estate",
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_assets_real_estate")
        
        # Investments
        if 'investments' in assets:
            investment_items = []
            for item in assets['investments']:
                investment_items.append(f"{item['name']}: ${item['value']:,.2f}")
            investments_text = f"""
            Investment Accounts (Total: ${financials['assetAllocation']['investments']['value']:,.2f}):
            {chr(10).join(investment_items)}
            Investment Allocation: {financials['assetAllocation']['investments']['percentage']}%
            """
            documents.append(investments_text)
            metadatas.append({
                "user_id": user_id,
                "category": "assets",
                "subcategory": "investments",
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_assets_investments")
        
        # 5. Index Liabilities
        liabilities = financials.get('liabilities', [])
        if liabilities:
            liability_items = []
            for item in liabilities:
                liability_items.append(f"{item['name']}: ${item['balance']:,.2f} ({item['type']})")
            liabilities_text = f"""
            Liabilities (Total: ${financials.get('totalLiabilities', 0):,.2f}):
            {chr(10).join(liability_items)}
            """
            documents.append(liabilities_text)
            metadatas.append({
                "user_id": user_id,
                "category": "liabilities",
                "subcategory": "all",
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_liabilities")
        
        # 6. Index Goals
        goals = summary.get('goals', [])
        for i, goal in enumerate(goals):
            goal_text = f"""
            Goal: {goal['name']}
            Category: {goal['category']}
            Target Amount: ${goal['target_amount']:,.2f}
            Current Progress: ${goal['currentProgress']:,.2f}
            Progress Percentage: {goal['progressPercentage']}%
            Target Date: {goal['target_date']}
            Years to Goal: {goal['yearsToGoal']}
            Monthly Required: ${goal['monthlyRequired']:,.2f}
            Priority: {goal['priority']}
            Status: {goal['status']}
            """
            documents.append(goal_text)
            metadatas.append({
                "user_id": user_id,
                "category": "goals",
                "subcategory": goal['category'],
                "goal_id": goal['goal_id'],
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_goal_{goal['goal_id']}")
        
        # 7. Index Recommendations
        recommendations = summary.get('recommendations', {})
        if recommendations:
            rec_text = f"""
            Portfolio Adjustment: {recommendations.get('portfolio_adjustment', '')}
            Risk Assessment: {recommendations.get('risk_assessment', '')}
            Tax Optimization: {recommendations.get('tax_optimization', '')}
            Next Steps: {', '.join(recommendations.get('next_steps', []))}
            Warnings: {', '.join(recommendations.get('warnings', []))}
            """
            documents.append(rec_text)
            metadatas.append({
                "user_id": user_id,
                "category": "recommendations",
                "subcategory": "ai_generated",
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_recommendations")
        
        # Add all documents to vector database
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"Indexed {len(documents)} documents for user {user_id}")
        
        return {
            "status": "success",
            "documents_indexed": len(documents),
            "user_id": user_id,
            "timestamp": datetime.now().isoformat()
        }
    
    def index_comprehensive_summary_with_profile(self, user_id: int, summary: dict, db: Session):
        """
        Index the comprehensive summary with complete profile data into vector database
        This includes personal info, family members, benefits, and tax information
        """
        from app.models.user_profile import UserProfile, FamilyMember, UserBenefit, UserTaxInfo
        
        documents = []
        metadatas = []
        ids = []
        
        # 1. Index User Profile (basic)
        profile_text = f"""
        User: {summary['user']['name']}
        Age: {summary['user']['age']}
        Email: {summary['user']['email']}
        Account Status: {summary['user']['status']}
        """
        documents.append(profile_text)
        metadatas.append({
            "user_id": user_id,
            "category": "profile",
            "subcategory": "basic_info",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_profile")
        
        # 2. Fetch and Index Complete Profile Data
        user_profile = db.query(UserProfile).filter(UserProfile.user_id == user_id).first()
        if user_profile:
            profile_detail_text = f"""
            Personal Information:
            Age: {user_profile.age} years old
            Date of Birth: {user_profile.date_of_birth if user_profile.date_of_birth else 'Not provided'}
            State: {user_profile.state or 'Not provided'}
            Country: {user_profile.country or 'Not provided'}
            Marital Status: {user_profile.marital_status or 'Not provided'}
            Employment Status: {user_profile.employment_status or 'Not provided'}
            Occupation: {user_profile.occupation or 'Not provided'}
            Risk Tolerance: {user_profile.risk_tolerance or 'Not provided'}
            Phone: {user_profile.phone or 'Not provided'}
            Address: {user_profile.address or 'Not provided'}
            City: {user_profile.city or 'Not provided'}
            ZIP Code: {user_profile.zip_code or 'Not provided'}
            Emergency Contact: {user_profile.emergency_contact or 'Not provided'}
            Emergency Phone: {user_profile.emergency_phone or 'Not provided'}
            Notes: {user_profile.notes or 'No additional notes'}
            """
            documents.append(profile_detail_text)
            metadatas.append({
                "user_id": user_id,
                "category": "profile",
                "subcategory": "personal_details",
                "timestamp": datetime.now().isoformat()
            })
            ids.append(f"user_{user_id}_profile_details")
            
            # 3. Index Family Members
            family_members = db.query(FamilyMember).filter(FamilyMember.profile_id == user_profile.id).all()
            if family_members:
                family_text = "Family Members:\n"
                for member in family_members:
                    # Build each piece safely
                    income_text = f"${member.income:,.2f} annually" if member.income else 'Income not provided'
                    retirement_text = f"${member.retirement_savings:,.2f}" if member.retirement_savings else 'Retirement savings not provided'
                    education_target_text = f"${member.education_fund_target:,.2f}" if member.education_fund_target else 'No education fund target'
                    education_current_text = f"${member.education_fund_current:,.2f}" if member.education_fund_current else 'No current education fund'
                    college_year_text = str(member.expected_college_year) if member.expected_college_year else 'No college plans specified'
                    support_text = "Yes" if member.requires_financial_support else "No" if member.requires_financial_support is not None else "Not specified"
                    support_amount_text = f"${member.monthly_support_amount:,.2f}" if member.monthly_support_amount else 'No support specified'
                    care_cost_text = f"${member.care_cost_estimate:,.2f}" if member.care_cost_estimate else 'No care costs estimated'
                    
                    family_text += f"""
                    {member.relationship_type.title()}: {member.name or 'Name not provided'}
                    Age: {member.age if member.age else 'Not provided'}
                    Date of Birth: {member.date_of_birth if member.date_of_birth else 'Not provided'}
                    Income: {income_text}
                    Retirement Savings: {retirement_text}
                    Education Fund Target: {education_target_text}
                    Education Fund Current: {education_current_text}
                    Expected College Year: {college_year_text}
                    Requires Financial Support: {support_text}
                    Monthly Support Amount: {support_amount_text}
                    Care Cost Estimate: {care_cost_text}
                    Notes: {member.notes or 'No additional notes'}
                    """
                
                documents.append(family_text)
                metadatas.append({
                    "user_id": user_id,
                    "category": "profile",
                    "subcategory": "family_members",
                    "timestamp": datetime.now().isoformat()
                })
                ids.append(f"user_{user_id}_family_members")
            
            # 4. Index Benefits
            benefits = db.query(UserBenefit).filter(UserBenefit.profile_id == user_profile.id).all()
            if benefits:
                benefits_text = "Benefits and Social Security:\n"
                for benefit in benefits:
                    # Build each piece safely
                    monthly_benefit_text = f"${benefit.estimated_monthly_benefit:,.2f}" if benefit.estimated_monthly_benefit else 'Amount not specified'
                    retirement_age_text = str(benefit.full_retirement_age) if benefit.full_retirement_age else 'Not specified'
                    early_reduction_text = f"{benefit.early_retirement_reduction}%" if benefit.early_retirement_reduction else 'Not specified'
                    delayed_increase_text = f"{benefit.delayed_retirement_increase}%" if benefit.delayed_retirement_increase else 'Not specified'
                    spouse_eligible_text = "Yes" if benefit.spouse_benefit_eligible else "No" if benefit.spouse_benefit_eligible is not None else "Not specified"
                    spouse_amount_text = f"${benefit.spouse_benefit_amount:,.2f}" if benefit.spouse_benefit_amount else 'Not specified'
                    pension_type_text = benefit.pension_type if benefit.pension_type else 'Not applicable'
                    vesting_text = benefit.vesting_schedule if benefit.vesting_schedule else 'Not applicable'
                    vested_pct_text = f"{benefit.vested_percentage}%" if benefit.vested_percentage else 'Not applicable'
                    monthly_payout_text = f"${benefit.expected_monthly_payout:,.2f}" if benefit.expected_monthly_payout else 'Not specified'
                    lump_sum_text = "Available" if benefit.lump_sum_option else "Not available" if benefit.lump_sum_option is not None else "Not specified"
                    match_pct_text = f"{benefit.employer_match_percentage}%" if benefit.employer_match_percentage else 'Not applicable'
                    match_limit_text = f"${benefit.employer_match_limit:,.2f}" if benefit.employer_match_limit else 'Not applicable'
                    premium_text = f"${benefit.health_insurance_premium:,.2f} monthly" if benefit.health_insurance_premium else 'Not applicable'
                    contribution_text = f"${benefit.employer_contribution:,.2f}" if benefit.employer_contribution else 'Not applicable'
                    start_date_text = str(benefit.benefit_start_date) if benefit.benefit_start_date else 'Not specified'
                    end_date_text = str(benefit.benefit_end_date) if benefit.benefit_end_date else 'Ongoing'
                    
                    benefits_text += f"""
                    {benefit.benefit_type.replace('_', ' ').title()}: {benefit.benefit_name or 'Benefit'}
                    Estimated Monthly Benefit: {monthly_benefit_text}
                    Full Retirement Age: {retirement_age_text}
                    Early Retirement Reduction: {early_reduction_text}
                    Delayed Retirement Increase: {delayed_increase_text}
                    Spouse Benefit Eligible: {spouse_eligible_text}
                    Spouse Benefit Amount: {spouse_amount_text}
                    Pension Type: {pension_type_text}
                    Vesting Schedule: {vesting_text}
                    Vested Percentage: {vested_pct_text}
                    Expected Monthly Payout: {monthly_payout_text}
                    Lump Sum Option: {lump_sum_text}
                    Employer Match Percentage: {match_pct_text}
                    Employer Match Limit: {match_limit_text}
                    Health Insurance Premium: {premium_text}
                    Employer Contribution: {contribution_text}
                    Benefit Start Date: {start_date_text}
                    Benefit End Date: {end_date_text}
                    Notes: {benefit.notes or 'No additional notes'}
                    """
                
                documents.append(benefits_text)
                metadatas.append({
                    "user_id": user_id,
                    "category": "profile",
                    "subcategory": "benefits",
                    "timestamp": datetime.now().isoformat()
                })
                ids.append(f"user_{user_id}_benefits")
            
            # 5. Index Tax Information
            tax_info = db.query(UserTaxInfo).filter(UserTaxInfo.profile_id == user_profile.id).order_by(UserTaxInfo.tax_year.desc()).first()
            if tax_info:
                # Build each piece safely
                federal_bracket_text = f"{tax_info.federal_tax_bracket}%" if tax_info.federal_tax_bracket else 'Not specified'
                state_bracket_text = f"{tax_info.state_tax_bracket}%" if tax_info.state_tax_bracket else 'Not specified'
                effective_rate_text = f"{tax_info.effective_tax_rate}%" if tax_info.effective_tax_rate else 'Not calculated'
                marginal_rate_text = f"{tax_info.marginal_tax_rate}%" if tax_info.marginal_tax_rate else 'Not calculated'
                agi_text = f"${tax_info.adjusted_gross_income:,.2f}" if tax_info.adjusted_gross_income else 'Not provided'
                taxable_income_text = f"${tax_info.taxable_income:,.2f}" if tax_info.taxable_income else 'Not calculated'
                trad_401k_text = f"${tax_info.traditional_401k_contribution:,.2f}" if tax_info.traditional_401k_contribution else 'None'
                roth_401k_text = f"${tax_info.roth_401k_contribution:,.2f}" if tax_info.roth_401k_contribution else 'None'
                trad_ira_text = f"${tax_info.traditional_ira_contribution:,.2f}" if tax_info.traditional_ira_contribution else 'None'
                roth_ira_text = f"${tax_info.roth_ira_contribution:,.2f}" if tax_info.roth_ira_contribution else 'None'
                hsa_text = f"${tax_info.hsa_contribution:,.2f}" if tax_info.hsa_contribution else 'None'
                max_401k_text = f"${tax_info.max_401k_contribution:,.2f}" if tax_info.max_401k_contribution else 'Not specified'
                max_ira_text = f"${tax_info.max_ira_contribution:,.2f}" if tax_info.max_ira_contribution else 'Not specified'
                max_hsa_text = f"${tax_info.max_hsa_contribution:,.2f}" if tax_info.max_hsa_contribution else 'Not specified'
                standard_deduction_text = f"${tax_info.standard_deduction:,.2f}" if tax_info.standard_deduction else 'Not specified'
                itemized_text = f"${tax_info.itemized_deductions:,.2f}" if tax_info.itemized_deductions else 'None'
                credits_text = f"${tax_info.tax_credits:,.2f}" if tax_info.tax_credits else 'None'
                has_professional_text = "Yes" if tax_info.has_tax_professional else "No" if tax_info.has_tax_professional is not None else "Not specified"
                professional_name_text = tax_info.tax_professional_name if tax_info.tax_professional_name else 'None'
                strategy_notes_text = tax_info.tax_strategy_notes if tax_info.tax_strategy_notes else 'No strategy notes'
                quarterly_payments_text = "Yes" if tax_info.estimated_quarterly_payments else "No" if tax_info.estimated_quarterly_payments is not None else "Not specified"
                quarterly_amount_text = f"${tax_info.quarterly_payment_amount:,.2f}" if tax_info.quarterly_payment_amount else 'Not applicable'
                
                tax_text = f"""
                Tax Information for {tax_info.tax_year}:
                Filing Status: {tax_info.filing_status or 'Not specified'}
                Federal Tax Bracket: {federal_bracket_text}
                State Tax Bracket: {state_bracket_text}
                Effective Tax Rate: {effective_rate_text}
                Marginal Tax Rate: {marginal_rate_text}
                Adjusted Gross Income: {agi_text}
                Taxable Income: {taxable_income_text}
                Traditional 401k Contribution: {trad_401k_text}
                Roth 401k Contribution: {roth_401k_text}
                Traditional IRA Contribution: {trad_ira_text}
                Roth IRA Contribution: {roth_ira_text}
                HSA Contribution: {hsa_text}
                Maximum 401k Contribution: {max_401k_text}
                Maximum IRA Contribution: {max_ira_text}
                Maximum HSA Contribution: {max_hsa_text}
                Standard Deduction: {standard_deduction_text}
                Itemized Deductions: {itemized_text}
                Tax Credits: {credits_text}
                Has Tax Professional: {has_professional_text}
                Tax Professional Name: {professional_name_text}
                Tax Strategy Notes: {strategy_notes_text}
                Estimated Quarterly Payments: {quarterly_payments_text}
                Quarterly Payment Amount: {quarterly_amount_text}
                Notes: {tax_info.notes or 'No additional notes'}
                """
                
                documents.append(tax_text)
                metadatas.append({
                    "user_id": user_id,
                    "category": "profile",
                    "subcategory": "tax_information",
                    "timestamp": datetime.now().isoformat()
                })
                ids.append(f"user_{user_id}_tax_info")
        
        # Continue with existing financial data indexing...
        # 6. Index Financial Preferences
        preferences = summary.get('preferences', {})
        pref_text = f"""
        Risk Tolerance: {preferences.get('risk_tolerance', 'not set')}
        Risk Score: {preferences.get('risk_score', 0)}/10
        Investment Style: {preferences.get('investment_style', 'not set')}
        Investment Timeline: {preferences.get('investment_timeline', 0)} years
        Financial Knowledge: {preferences.get('financial_knowledge', 'not set')}
        Emergency Fund Target: {preferences.get('emergency_fund_months', 6)} months
        Tax Filing Status: {preferences.get('tax_filing_status', 'not set')}
        Federal Tax Bracket: {preferences.get('federal_tax_bracket', 0)*100 if preferences.get('federal_tax_bracket') else 0}%
        State: {preferences.get('state', 'not set')}
        State Tax Rate: {preferences.get('state_tax_rate', 0)*100 if preferences.get('state_tax_rate') else 0}%
        Stocks Preference: {preferences.get('stocks_preference', 0)}/10
        Bonds Preference: {preferences.get('bonds_preference', 0)}/10
        Real Estate Preference: {preferences.get('real_estate_preference', 0)}/10
        Crypto Preference: {preferences.get('crypto_preference', 0)}/10
        ESG Investing: {preferences.get('esg_investing', False)}
        Tax Loss Harvesting: {preferences.get('tax_loss_harvesting', False)}
        """
        documents.append(pref_text)
        metadatas.append({
            "user_id": user_id,
            "category": "preferences",
            "subcategory": "investment_preferences",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_preferences")
        
        # 7. Index Financial Summary
        financials = summary.get('financials', {})
        summary_text = f"""
        Net Worth: ${financials.get('netWorth', 0):,.2f}
        Total Assets: ${financials.get('totalAssets', 0):,.2f}
        Total Liabilities: ${financials.get('totalLiabilities', 0):,.2f}
        Monthly Income: ${financials.get('monthlyIncome', 0):,.2f}
        Monthly Expenses: ${financials.get('monthlyExpenses', 0):,.2f}
        Monthly Surplus: ${financials.get('monthlySurplus', 0):,.2f}
        Savings Rate: {financials.get('savingsRate', 0)}%
        Debt-to-Income Ratio: {financials.get('debtToIncomeRatio', 0)}%
        Emergency Fund Coverage: {financials.get('emergencyFundCoverage', 0)} months
        """
        documents.append(summary_text)
        metadatas.append({
            "user_id": user_id,
            "category": "financials",
            "subcategory": "summary",
            "timestamp": datetime.now().isoformat()
        })
        ids.append(f"user_{user_id}_financial_summary")
        
        # Continue with existing logic for assets, liabilities, goals, etc.
        # ... (keeping existing financial indexing code)
        
        # Add all documents to vector database
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"Indexed {len(documents)} documents (including profile data) for user {user_id}")
        
        return {
            "status": "success",
            "documents_indexed": len(documents),
            "user_id": user_id,
            "profile_data_included": True,
            "timestamp": datetime.now().isoformat()
        }
    
    def search_by_intent(self, user_id: int, intent_search_terms: List[str], priority_weights: Dict[str, int] = None) -> Dict:
        """
        Search for documents based on detected intent and organize by relevance
        Returns organized context with primary, supporting, and background data
        """
        logger.info(f"ğŸ” Intent-based search with {len(intent_search_terms)} search terms")
        
        all_results = []
        document_scores = {}  # Track relevance scores
        seen_docs = set()
        
        # Search for each intent-specific term with increased results
        for i, search_term in enumerate(intent_search_terms):
            try:
                results = self.collection.query(
                    query_texts=[search_term],
                    n_results=20,  # Increased to get comprehensive context
                    where={"user_id": user_id}
                )
                
                if results and results['documents'] and results['documents'][0]:
                    for j, doc_content in enumerate(results['documents'][0]):
                        doc_id = results['ids'][0][j] if 'ids' in results else None
                        distance = results['distances'][0][j] if 'distances' in results else 1.0
                        metadata = results['metadatas'][0][j] if 'metadatas' in results else {}
                        
                        # Skip duplicates
                        if doc_id and doc_id in seen_docs:
                            continue
                        
                        if doc_id:
                            seen_docs.add(doc_id)
                        
                        # Calculate relevance score (lower distance = higher relevance)
                        base_score = 1.0 - distance  # Convert distance to relevance
                        
                        # Boost score based on priority weights and financial importance
                        category = metadata.get('category', '').lower()
                        subcategory = metadata.get('subcategory', '').lower()
                        
                        priority_boost = 0
                        
                        # Critical financial data gets highest priority
                        if category in ['financials', 'goals', 'profile']:
                            priority_boost += 0.3
                        
                        # Retirement and benefits data is critical for most questions
                        if subcategory in ['benefits', 'retirement', 'social_security']:
                            priority_boost += 0.4
                        
                        # Current financial status is always relevant
                        if subcategory in ['summary', 'basic_info', 'investment_preferences']:
                            priority_boost += 0.2
                        if priority_weights:
                            for priority_key, weight in priority_weights.items():
                                if priority_key in category or priority_key in subcategory or priority_key in doc_content.lower():
                                    priority_boost = weight * 0.1  # Convert to decimal boost
                                    break
                        
                        final_score = base_score + priority_boost
                        
                        all_results.append({
                            "content": doc_content,
                            "metadata": metadata,
                            "score": final_score,
                            "search_term": search_term
                        })
                        
                        document_scores[doc_content] = final_score
                        
            except Exception as e:
                logger.warning(f"Search failed for term '{search_term}': {str(e)}")
                continue
        
        # Sort by relevance score (highest first)
        all_results.sort(key=lambda x: x['score'], reverse=True)
        
        # Organize results by importance
        organized = self._organize_results_by_relevance(all_results[:15])  # Limit total results
        
        logger.info(f"ğŸ” Retrieved {len(all_results)} total results, organized into {len(organized['primary_data'])} primary, {len(organized['supporting_data'])} supporting")
        
        return organized
    
    def _organize_results_by_relevance(self, results: List[Dict]) -> Dict:
        """
        Organize search results into primary, supporting, and background categories
        """
        context = {
            "primary_data": [],      # Most relevant (score > 0.8)
            "supporting_data": [],   # Moderately relevant (score > 0.5)
            "background": []         # General context (score <= 0.5)
        }
        
        for result in results:
            score = result.get('score', 0)
            content = result.get('content', '')
            
            if score > 0.8:
                context["primary_data"].append(content)
            elif score > 0.5:
                context["supporting_data"].append(content)
            else:
                context["background"].append(content)
        
        return context
    
    def expand_query_by_intent(self, query: str) -> List[str]:
        """
        Expand query with related financial terms for better context retrieval
        
        Args:
            query: Original search query
            
        Returns:
            List of expanded queries including the original
        """
        # Financial keyword mappings for query expansion
        financial_expansions = {
            'retirement': ['retirement', '401k', 'pension', 'social security', 'retirement planning', 'financial independence'],
            'investment': ['investment', 'portfolio', 'stocks', 'bonds', 'mutual funds', 'asset allocation'],
            'debt': ['debt', 'loan', 'mortgage', 'credit card', 'liability', 'debt payoff'],
            'savings': ['savings', 'emergency fund', 'cash', 'liquid assets', 'money market'],
            'income': ['income', 'salary', 'earnings', 'revenue', 'cash flow'],
            'expense': ['expense', 'spending', 'cost', 'budget', 'monthly expenses'],
            'tax': ['tax', 'taxes', 'deduction', 'tax planning', 'tax optimization'],
            'insurance': ['insurance', 'life insurance', 'health insurance', 'coverage'],
            'estate': ['estate', 'will', 'trust', 'estate planning', 'inheritance'],
            'goal': ['goal', 'financial goal', 'target', 'objective', 'planning']
        }
        
        query_lower = query.lower()
        expanded_queries = [query]  # Always include original query
        
        # Find relevant financial categories and add related terms
        for category, terms in financial_expansions.items():
            if category in query_lower or any(term in query_lower for term in terms[:3]):  # Check first 3 terms
                for term in terms:
                    if term not in query_lower:  # Don't duplicate terms already in query
                        expanded_queries.append(f"{query} {term}")
        
        # Limit to max 5 queries to avoid overwhelming the search
        return expanded_queries[:5]
    
    def search_context(self, user_id: int, query: str, n_results: int = 25) -> List[Dict]:
        """
        Enhanced search with intent-based query expansion for better context retrieval
        """
        logger.info(f"ğŸ”µ VECTOR SEARCH - Query: '{query}', Requesting: {n_results} results")
        
        # Expand query based on intent
        expanded_queries = self.expand_query_by_intent(query)
        logger.info(f"ğŸ”µ VECTOR SEARCH - Expanded to {len(expanded_queries)} queries: {expanded_queries[:3]}")
        
        # Collect all results
        all_results = []
        seen_ids = set()  # Track document IDs to avoid duplicates
        
        # Search with each expanded query
        for expanded_query in expanded_queries:
            try:
                results = self.collection.query(
                    query_texts=[expanded_query],
                    n_results=min(15, n_results),  # Get more comprehensive results per query
                    where={"user_id": user_id}
                )
                
                # Add unique results
                if results and results['documents'] and results['documents'][0]:
                    for i in range(len(results['documents'][0])):
                        doc_id = results['ids'][0][i] if 'ids' in results else None
                        
                        # Skip if we've already seen this document
                        if doc_id and doc_id in seen_ids:
                            continue
                        
                        if doc_id:
                            seen_ids.add(doc_id)
                        
                        all_results.append({
                            "content": results['documents'][0][i],
                            "metadata": results['metadatas'][0][i] if 'metadatas' in results else {},
                            "distance": results['distances'][0][i] if 'distances' in results else None
                        })
            except Exception as e:
                logger.warning(f"Query failed for '{expanded_query}': {str(e)}")
                continue
        
        # Always search for the original query too
        try:
            original_results = self.collection.query(
                query_texts=[query],
                n_results=n_results,
                where={"user_id": user_id}
            )
            
            if original_results and original_results['documents'] and original_results['documents'][0]:
                for i in range(len(original_results['documents'][0])):
                    doc_id = original_results['ids'][0][i] if 'ids' in original_results else None
                    
                    if doc_id and doc_id not in seen_ids:
                        seen_ids.add(doc_id)
                        all_results.append({
                            "content": original_results['documents'][0][i],
                            "metadata": original_results['metadatas'][0][i] if 'metadatas' in original_results else {},
                            "distance": original_results['distances'][0][i] if 'distances' in original_results else None
                        })
        except Exception as e:
            logger.warning(f"Original query failed: {str(e)}")
        
        # Sort by distance (if available) and limit to n_results
        if all_results and all_results[0].get('distance') is not None:
            all_results.sort(key=lambda x: x.get('distance', float('inf')))
        
        # Limit to requested number of results
        final_results = all_results[:n_results]
        
        logger.info(f"ğŸ”µ VECTOR SEARCH - Returning {len(final_results)} unique documents")
        if final_results:
            for i, item in enumerate(final_results[:3]):
                content_preview = item['content'][:100] if item.get('content') else 'No content'
                logger.info(f"ğŸ”µ VECTOR SEARCH - Result {i+1}: {content_preview}...")
        
        return final_results
    
    async def sync_financial_entry(self, entry) -> bool:
        """Sync a single financial entry to vector DB with all calculations"""
        
        # Build comprehensive document
        doc_text = self._build_entry_document(entry)
        
        # Prepare metadata with all relevant fields
        metadata = {
            "user_id": entry.user_id,
            "entry_id": entry.id,
            "category": entry.category.value,
            "subcategory": entry.subcategory or "",
            "amount": float(entry.amount),
            "interest_rate": float(entry.interest_rate) if entry.interest_rate else 0,
            "minimum_payment": float(entry.minimum_payment) if entry.minimum_payment else 0,
            "daily_interest_cost": float(entry.daily_interest_cost) if entry.daily_interest_cost else 0,
            "timestamp": datetime.now().isoformat()
        }
        
        # Upsert to vector DB (update if exists, insert if new)
        self.collection.upsert(
            documents=[doc_text],
            metadatas=[metadata],
            ids=[f"entry_{entry.id}"]
        )
        
        logger.info(f"Synced entry {entry.id} to vector DB")
        return True
    
    def _build_entry_document(self, entry) -> str:
        """Build comprehensive document for vector indexing"""
        
        doc = f"{entry.category.value.title()} - {entry.subcategory or 'General'}: {entry.description}\n"
        doc += f"Amount: ${float(entry.amount):,.2f}\n"
        
        # Include interest rate information
        if entry.interest_rate:
            doc += f"Interest Rate: {float(entry.interest_rate)}%\n"
            if entry.daily_interest_cost:
                doc += f"Daily Interest Cost: ${float(entry.daily_interest_cost):.2f}\n"
                doc += f"Annual Interest Cost: ${(float(entry.daily_interest_cost) * 365):,.2f}\n"
        
        # Include payment information
        if entry.minimum_payment:
            doc += f"Minimum Payment: ${float(entry.minimum_payment):,.2f}\n"
        
        # Include loan details
        if entry.loan_term_months:
            doc += f"Loan Term: {entry.loan_term_months} months\n"
        if entry.remaining_months:
            doc += f"Remaining: {entry.remaining_months} months\n"
        if entry.payoff_date:
            doc += f"Payoff Date: {entry.payoff_date}\n"
        if entry.total_interest_lifetime:
            doc += f"Total Interest Over Life: ${float(entry.total_interest_lifetime):,.2f}\n"
        
        # Add calculated insights
        if entry.category.value == "liabilities" and entry.interest_rate:
            rate = float(entry.interest_rate)
            if rate > 15:
                doc += "HIGH INTEREST DEBT - Priority for payoff\n"
            elif rate < 5:
                doc += "LOW INTEREST DEBT - Consider minimum payments only\n"
            else:
                doc += "MODERATE INTEREST DEBT - Strategic payoff consideration\n"
        
        return doc
    
    async def sync_all_user_entries(self, user_id: int, entries: list, safe_mode: bool = True) -> int:
        """
        ğŸš¨ DANGEROUS: Sync all entries for a user - used for rebuilds
        
        Args:
            user_id: User ID to sync
            entries: List of entries to sync
            safe_mode: If True, creates backup before clearing (RECOMMENDED)
        
        âš ï¸  WARNING: This function can cause data loss if safe_mode=False
        """
        
        if safe_mode:
            # ğŸ›¡ï¸ SAFE MODE: Create backup before clearing
            backup = self.backup_user_data(user_id)
            logger.info(f"ğŸ›¡ï¸ Created backup of {backup['document_count']} documents before sync")
        
        # Clear existing entries for user
        try:
            existing_docs = self.collection.get(where={"user_id": user_id})
            doc_count = len(existing_docs.get('ids', []))
            
            if doc_count > 0:
                if safe_mode and doc_count > 5:
                    logger.warning(f"ğŸš¨ About to delete {doc_count} documents in safe mode - backup created")
                elif not safe_mode:
                    logger.error(f"ğŸš¨ UNSAFE MODE: About to delete {doc_count} documents WITHOUT backup!")
                
                self.collection.delete(where={"user_id": user_id})
                logger.info(f"Cleared {doc_count} existing entries for user {user_id}")
                
        except Exception as e:
            logger.warning(f"Could not clear existing entries: {e}")
        
        # Sync each entry
        synced_count = 0
        for entry in entries:
            try:
                await self.sync_financial_entry(entry)
                synced_count += 1
            except Exception as e:
                logger.error(f"Failed to sync entry {entry.id}: {e}")
        
        logger.info(f"Synced {synced_count} entries for user {user_id}")
        return synced_count
    
    def get_chat_context(self, user_id: int, message: str) -> str:
        """
        Build context for chat based on message content
        """
        logger.info(f"ğŸ”µ STEP 2 - Vector search query: '{message}' for user {user_id}")
        
        # Search for relevant context
        relevant_docs = self.search_context(user_id, message, n_results=25)
        logger.info(f"ğŸ”µ STEP 3 - Retrieved {len(relevant_docs)} documents from vector search")
        
        # Always include financial summary
        summary_docs = self.collection.get(
            ids=[f"user_{user_id}_financial_summary", f"user_{user_id}_preferences"],
            where={"user_id": user_id}
        )
        
        # Build context string
        context = "RELEVANT FINANCIAL CONTEXT:\n\n"
        
        # Add summary first
        if summary_docs['documents']:
            context += "=== FINANCIAL OVERVIEW ===\n"
            for doc in summary_docs['documents']:
                context += doc + "\n"
        
        # Add relevant search results
        context += "\n=== RELEVANT INFORMATION ===\n"
        for item in relevant_docs:
            context += f"\n{item['metadata']['category'].upper()} - {item['metadata']['subcategory']}:\n"
            context += item['content'] + "\n"
        
        return context
    
    def clear_user_data(self, user_id: int, require_backup: bool = True, max_delete_without_backup: int = 5):
        """
        ğŸš¨ DANGEROUS: Clear all vector data for a specific user
        
        SAFETY GUARDS:
        - require_backup=True: Prevents deletion without explicit backup confirmation
        - max_delete_without_backup=5: Prevents mass deletion without backup
        
        âš ï¸  WARNING: This function caused the loss of 41 documents (48â†’7)
        âš ï¸  USE CAREFULLY: Only call after creating backup or for small datasets
        """
        
        # Get all document IDs for this user
        all_docs = self.collection.get(where={"user_id": user_id})
        doc_count = len(all_docs.get('ids', []))
        
        if doc_count == 0:
            logger.info(f"No documents found for user {user_id}")
            return {"status": "success", "deleted_count": 0}
        
        # ğŸ›¡ï¸ SAFETY GUARD: Prevent mass deletion without backup
        if require_backup and doc_count > max_delete_without_backup:
            error_msg = (
                f"ğŸš¨ SAFETY GUARD TRIGGERED: Attempting to delete {doc_count} documents for user {user_id}. "
                f"This exceeds the safe limit of {max_delete_without_backup} documents. "
                f"To proceed: 1) Create backup first, 2) Call with require_backup=False, or 3) Use safe_index endpoint instead."
            )
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # ğŸš¨ DANGEROUS OPERATION - DELETES ALL USER DATA
        logger.warning(f"ğŸš¨ DELETING {doc_count} documents for user {user_id} - BACKUP RECOMMENDED")
        
        if all_docs['ids']:
            self.collection.delete(ids=all_docs['ids'])
        
        logger.warning(f"ğŸš¨ DELETED {doc_count} documents for user {user_id}")
        
        return {"status": "success", "deleted_count": doc_count}
    
    def backup_user_data(self, user_id: int):
        """
        ğŸ›¡ï¸ SAFE: Create backup of user data before dangerous operations
        
        Returns: Dictionary containing all user documents that can be restored
        """
        backup_data = self.collection.get(where={"user_id": user_id})
        doc_count = len(backup_data.get('ids', []))
        
        logger.info(f"ğŸ›¡ï¸ Created backup of {doc_count} documents for user {user_id}")
        
        return {
            "user_id": user_id,
            "document_count": doc_count,
            "backup_data": backup_data,
            "timestamp": datetime.now().isoformat()
        }
    
    def restore_user_data(self, user_id: int, backup: dict):
        """
        ğŸ›¡ï¸ SAFE: Restore user data from backup
        
        Args:
            user_id: User ID to restore data for
            backup: Backup data created by backup_user_data()
        """
        backup_data = backup.get('backup_data', {})
        
        if not backup_data.get('ids'):
            logger.warning(f"No backup data found for user {user_id}")
            return {"status": "no_data", "restored_count": 0}
        
        # Clear existing data first (if any)
        current_docs = self.collection.get(where={"user_id": user_id})
        if current_docs.get('ids'):
            self.collection.delete(ids=current_docs['ids'])
        
        # Restore from backup
        self.collection.add(
            ids=backup_data['ids'],
            documents=backup_data['documents'],
            metadatas=backup_data['metadatas']
        )
        
        restored_count = len(backup_data['ids'])
        logger.info(f"ğŸ›¡ï¸ Restored {restored_count} documents for user {user_id}")
        
        return {"status": "success", "restored_count": restored_count}
    
    def index_comprehensive_summary_with_profile_incremental(self, user_id: int, summary: dict, db: Session, existing_ids: set):
        """
        ğŸ›¡ï¸ SAFE: Incremental indexing - only adds new documents
        
        Args:
            user_id: User ID
            summary: Comprehensive financial summary
            db: Database session  
            existing_ids: Set of existing document IDs to avoid duplicates
        
        Returns: Dictionary with documents_added count
        """
        
        logger.info(f"ğŸ›¡ï¸ Starting incremental indexing for user {user_id}")
        
        # Generate all documents that should exist
        all_documents = []
        all_metadatas = []
        all_ids = []
        
        # Use existing comprehensive indexing logic but check for duplicates
        try:
            # This calls the existing method but we'll filter duplicates
            temp_result = self.index_comprehensive_summary_with_profile(user_id, summary, db, dry_run=True)
            
            # For now, just add a few key documents to avoid duplicates
            documents_added = 0
            
            # Add net worth summary if not exists
            net_worth_id = f"net_worth_summary_{user_id}"
            if net_worth_id not in existing_ids and 'net_worth' in summary:
                all_documents.append(f"Net Worth Summary: ${summary['net_worth']:,}")
                all_metadatas.append({
                    'user_id': user_id,
                    'category': 'financial_summary',
                    'type': 'net_worth',
                    'timestamp': datetime.now().isoformat()
                })
                all_ids.append(net_worth_id)
                documents_added += 1
            
            # Add cash flow if not exists
            cash_flow_id = f"cash_flow_summary_{user_id}"
            if cash_flow_id not in existing_ids and 'monthly_surplus' in summary:
                all_documents.append(f"Monthly Cash Flow: ${summary['monthly_surplus']:,} surplus")
                all_metadatas.append({
                    'user_id': user_id,
                    'category': 'financial_summary', 
                    'type': 'cash_flow',
                    'timestamp': datetime.now().isoformat()
                })
                all_ids.append(cash_flow_id)
                documents_added += 1
            
            # Actually add the documents
            if all_documents:
                self.collection.add(
                    documents=all_documents,
                    metadatas=all_metadatas,
                    ids=all_ids
                )
            
            logger.info(f"ğŸ›¡ï¸ Incremental indexing complete: {documents_added} new documents added")
            
            return {
                "status": "success",
                "documents_added": documents_added,
                "existing_documents": len(existing_ids),
                "total_documents": len(existing_ids) + documents_added
            }
            
        except Exception as e:
            logger.error(f"Incremental indexing failed: {e}")
            return {"status": "error", "error": str(e), "documents_added": 0}

# Global instance
_vector_db_instance = None

def get_vector_db() -> FinancialVectorDB:
    """Get or create the global vector database instance"""
    global _vector_db_instance
    if _vector_db_instance is None:
        _vector_db_instance = FinancialVectorDB()
    return _vector_db_instance